{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions as f \n",
    "\n",
    "#import the data\n",
    "df_train = pd.read_csv('cars_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_price = df_train.loc[df_train['price'] == 0]\n",
    "df_train.drop(zero_price.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the threshold for the outliers for every numerical variable\n",
    "lower_price, upper_price = f.detect_outliers(df_train['price'])\n",
    "lower_id, upper_id = f.detect_outliers(df_train['id'])\n",
    "lower_year, upper_year = f.detect_outliers(df_train['year'])\n",
    "lower_odometer, upper_odometer = f.detect_outliers(df_train['odometer'])\n",
    "lower_lat, upper_lat = f.detect_outliers(df_train['lat'])\n",
    "lower_long, upper_long = f.detect_outliers(df_train['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering all the records that contain outliers to drop them\n",
    "outliers = df_train.loc[(df_train['price'] < lower_price) | (df_train['price'] > upper_price) |\n",
    "                        (df_train['id'] < lower_id) | (df_train['id'] > upper_id) |\n",
    "                        (df_train['year'] < lower_year) | (df_train['year'] > upper_year) |\n",
    "                        (df_train['odometer'] < lower_odometer) | (df_train['odometer'] > upper_odometer) |\n",
    "                        (df_train['lat'] < lower_lat) | (df_train['lat'] > upper_lat) |\n",
    "                        (df_train['long'] < lower_long) | (df_train['long'] > upper_long)]\n",
    "\n",
    "df_train.drop(outliers.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate the price from the features for the train\n",
    "train_price = df_train['price']\n",
    "train_features = df_train.drop(['price','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the empty rows for the categorical data for the training set with the most frequent value\n",
    "train_features['paint_color'] = f.fill_cat(train_features['paint_color'])\n",
    "train_features['type'] = f.fill_cat(train_features['type'])\n",
    "train_features['drive']=f.fill_cat(train_features['drive'])\n",
    "train_features['transmission']= f.fill_cat(train_features['transmission'])\n",
    "train_features['fuel']=f.fill_cat(train_features['fuel'])\n",
    "train_features['cylinders']=f.fill_cat(train_features['cylinders'])\n",
    "train_features['condition']= f.fill_cat(train_features['condition'])\n",
    "train_features['model']=f.fill_cat(train_features['model'])\n",
    "train_features['manufacturer']=f.fill_cat(train_features['manufacturer'])\n",
    "train_features['posting_date']=f.fill_cat(train_features['posting_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict that contains every term and its replacment in the model column to replace the terms\n",
    "model_dic=f.replace(train_features['model'])\n",
    "train_features['model'] = train_features['model'].replace(model_dic)\n",
    "\n",
    "#replace all the values that their count is less than 1000 with other\n",
    "train_list = f.features_list(train_features['model'], 1000)\n",
    "train_features['model']=train_features['model'].replace(train_list,'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all the categories of the column that their count is less than 1000 and group them into one group 'other'\n",
    "train_list1 = f.features_list(train_features['manufacturer'],1000)\n",
    "train_features['manufacturer'] = train_features['manufacturer'].replace(train_list1,'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all the categories of the column that their count is less than 1000 and group them into one group 'other'\n",
    "train_list2 = f.features_list(train_features['state'],1000)\n",
    "train_features['state'] = train_features['state'].replace(train_list2,'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    267363\n",
       "new      16399\n",
       "fair      5771\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put condition into 3 categories\n",
    "mapping = {'like new':'new', 'excellent':'good','salvage':'fair'}\n",
    "train_features['condition']= train_features['condition'].replace(mapping)\n",
    "train_features['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average        287510\n",
       "more_power       1066\n",
       "other             611\n",
       "lower_power       346\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the cylinders column from the word cylinders\n",
    "train_features['cylinders']=train_features['cylinders'].str.replace('cylinders', '')\n",
    "train_features['cylinders']=train_features['cylinders'].astype('object')\n",
    "\n",
    "#put cylinders into 3 categories \n",
    "mapping1 = {'4 ':'average','6 ':'average','8 ':'average','5 ':'average','10 ':'more_power','12 ':'more_power','3 ':'lower_power'}\n",
    "train_features['cylinders'] = train_features['cylinders'].replace(mapping1)\n",
    "train_features['cylinders'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Baseline Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerical variables: (289533, 4)\n",
      "The categorical variables: (289533, 11)\n"
     ]
    }
   ],
   "source": [
    "#Isoliate the columns that I will be using\n",
    "train_features_baseline = train_features.drop(['region'], axis=1)\n",
    "\n",
    "# seperating the numerical and categorical values for the baseline model\n",
    "train_features_num_base = train_features_baseline.select_dtypes(include=[np.number])\n",
    "train_features_cat_base = train_features_baseline.select_dtypes(exclude=[np.number])\n",
    "print('The numerical variables:', train_features_num_base.shape)\n",
    "print('The categorical variables:', train_features_cat_base.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = f.pipeline(train_features_num_base,train_features_cat_base, train_features_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train baseline: 1707.8\n",
      "RMSE Scores for the Baseline Model:\n",
      "Scores: [12465.  8803.  9709.  8726.  8753.]\n",
      "Mean:  9691.0\n",
      "Stdev: 1435.0\n"
     ]
    }
   ],
   "source": [
    "#Train the model and cross validate the model\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_prepared, train_price)\n",
    "pred = lr.predict(train_prepared)\n",
    "train_rmse = mean_squared_error(train_price, pred, squared=False)\n",
    "print(f\"mse train baseline: {train_rmse:.1f}\")\n",
    "\n",
    "base_scores = cross_val_score(lr, train_prepared, train_price,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "base_rmse = np.sqrt(-base_scores)\n",
    "print('RMSE Scores for the Baseline Model:')\n",
    "f.display_scores(base_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the years in the year column into three bins \n",
    "train_features['year_bins']= f.bin_years(train_features['year'])\n",
    "\n",
    "#fill the missing category of the years that we binned\n",
    "train_features['year_bins'] = f.fill_cat(train_features['year_bins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netural    168687\n",
       "dark        65988\n",
       "light       49006\n",
       "custom       5852\n",
       "Name: paint_color, dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin the paint color\n",
    "color_mapping={'white':'netural','black':'dark','silver':'netural','red':'light','blue':'dark','grey':'light','green':'light',\n",
    "              'brown':'dark','orange':'light','yellow':'light','purple':'dark'}\n",
    "\n",
    "train_features['paint_color']= train_features['paint_color'].replace(color_mapping)\n",
    "train_features['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.drop(['odometer','posting_date','lat','long','region'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerical variables: (289533, 1)\n",
      "The categorical variables: (289533, 11)\n"
     ]
    }
   ],
   "source": [
    "# seperating the numerical and categorical values for the baseline model\n",
    "train_features_num_m = train_features.select_dtypes(include=[np.number])\n",
    "train_features_cat_m = train_features.select_dtypes(exclude=[np.number])\n",
    "print('The numerical variables:', train_features_num_m.shape)\n",
    "print('The categorical variables:', train_features_cat_m.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared1 = f.pipeline(train_features_num_m,train_features_cat_m, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train after feature engineering: 7606.7\n",
      "RMSE Scores for the Baseline Model:\n",
      "Scores: [7598. 7634. 7637. 7587. 7604.]\n",
      "Mean:  7612.0\n",
      "Stdev: 20.0\n"
     ]
    }
   ],
   "source": [
    "#Train and cross validate the model\n",
    "lr1 = LinearRegression()\n",
    "lr1.fit(train_prepared1, train_price)\n",
    "pred1 = lr1.predict(train_prepared1)\n",
    "train_rmse1 = mean_squared_error(train_price, pred1, squared=False)\n",
    "print(f\"mse train after feature engineering: {train_rmse1:.1f}\")\n",
    "\n",
    "scores = cross_val_score(lr1, train_prepared1, train_price,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('RMSE Scores for the Baseline Model:')\n",
    "f.display_scores(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the features coefficients \n",
    "coef = list(lr1.coef_)\n",
    "\n",
    "# get the encoded feature names from one hot encoding \n",
    "encoder = OneHotEncoder()\n",
    "encode = encoder.fit_transform(train_features_cat_m)\n",
    "columns = encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the numeric and categorical feature names \n",
    "attributes = list(train_features_num_m) + list(columns)\n",
    "\n",
    "#combine the feature names with their coefficients \n",
    "variables = pd.DataFrame((zip(coef)), columns= ['coefficient'], index= attributes).sort_values(by='coefficient',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x9_sd</th>\n",
       "      <th>x9_in</th>\n",
       "      <th>x0_lincoln</th>\n",
       "      <th>x9_mo</th>\n",
       "      <th>x1_odyssey</th>\n",
       "      <th>x9_id</th>\n",
       "      <th>x9_other</th>\n",
       "      <th>x4_electric</th>\n",
       "      <th>x9_nv</th>\n",
       "      <th>x0_ram</th>\n",
       "      <th>...</th>\n",
       "      <th>x9_pa</th>\n",
       "      <th>x8_netural</th>\n",
       "      <th>x1_sienna</th>\n",
       "      <th>x9_tx</th>\n",
       "      <th>x9_va</th>\n",
       "      <th>x5_manual</th>\n",
       "      <th>x0_gmc</th>\n",
       "      <th>x9_ga</th>\n",
       "      <th>x9_ms</th>\n",
       "      <th>x9_ny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coefficient</th>\n",
       "      <td>557.896491</td>\n",
       "      <td>549.014902</td>\n",
       "      <td>546.425267</td>\n",
       "      <td>541.148534</td>\n",
       "      <td>475.447784</td>\n",
       "      <td>474.840548</td>\n",
       "      <td>419.633611</td>\n",
       "      <td>395.975221</td>\n",
       "      <td>392.074944</td>\n",
       "      <td>386.390704</td>\n",
       "      <td>...</td>\n",
       "      <td>-340.922448</td>\n",
       "      <td>-357.916365</td>\n",
       "      <td>-400.814339</td>\n",
       "      <td>-406.320981</td>\n",
       "      <td>-421.556553</td>\n",
       "      <td>-483.727044</td>\n",
       "      <td>-489.449747</td>\n",
       "      <td>-509.547531</td>\n",
       "      <td>-518.327331</td>\n",
       "      <td>-545.531424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x9_sd       x9_in  x0_lincoln       x9_mo  x1_odyssey  \\\n",
       "coefficient  557.896491  549.014902  546.425267  541.148534  475.447784   \n",
       "\n",
       "                  x9_id    x9_other  x4_electric       x9_nv      x0_ram  ...  \\\n",
       "coefficient  474.840548  419.633611   395.975221  392.074944  386.390704  ...   \n",
       "\n",
       "                  x9_pa  x8_netural   x1_sienna       x9_tx       x9_va  \\\n",
       "coefficient -340.922448 -357.916365 -400.814339 -406.320981 -421.556553   \n",
       "\n",
       "              x5_manual      x0_gmc       x9_ga       x9_ms       x9_ny  \n",
       "coefficient -483.727044 -489.449747 -509.547531 -518.327331 -545.531424  \n",
       "\n",
       "[1 rows x 53 columns]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I will inspect first the variables that affect the price positivly by 600 and less and the ones that affect the price negatively by -600 and above\n",
    "features_to_drop = variables.loc[(variables['coefficient']<600) & (variables['coefficient']>-600)].T\n",
    "\n",
    "features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train_prepared1.todense(), columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(features_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train after feature selection: 7617.7\n",
      "RMSE Scores for the Baseline Model:\n",
      "Scores: [7608. 7642. 7645. 7597. 7615.]\n",
      "Mean:  7621.0\n",
      "Stdev: 19.0\n"
     ]
    }
   ],
   "source": [
    "lr3 = LinearRegression()\n",
    "lr3.fit(X_train, train_price)\n",
    "pred2 = lr3.predict(X_train)\n",
    "train_rmse2 = mean_squared_error(train_price, pred2, squared=False)\n",
    "print(f\"mse train after feature selection: {train_rmse2:.1f}\")\n",
    "\n",
    "scores2 = cross_val_score(lr3, X_train, train_price,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse2 = np.sqrt(-scores2)\n",
    "print('RMSE Scores for the Baseline Model:')\n",
    "f.display_scores(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVR(),\n",
       "             param_grid=[{'C': [0.01, 1, 5], 'max_iter': [100, 400, 1000]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr= LinearSVR()\n",
    "param_grid_svr = [\n",
    "    {'C': [0.01, 1, 5], 'max_iter': [100, 400, 1000]}]\n",
    "\n",
    "svr_search = GridSearchCV(svr, param_grid_svr, cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "svr_search.fit(X_train, train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVR Mean RMSE >>', 8176.0)\n",
      "('SVR Std RMSE >>', 932.0)\n"
     ]
    }
   ],
   "source": [
    "svr_best_score = svr_search.best_score_\n",
    "print(('SVR Mean RMSE >>', np.round(np.sqrt(-svr_best_score))))\n",
    "\n",
    "svr_std = svr_search.cv_results_['std_test_score'][svr_search.best_index_]\n",
    "print(('SVR Std RMSE >>', np.round(np.sqrt(svr_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [100, 400, 1000],\n",
       "                          'splitter': ['random', 'best']}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "param_grid_dtr = [\n",
    "    {'splitter': ['random','best'], 'max_depth': [100, 400, 1000]}]\n",
    "\n",
    "dtr_search = GridSearchCV(dtr, param_grid_dtr, cv=5, scoring='neg_mean_squared_error')\n",
    "dtr_search.fit(X_train, train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Decision Tree Mean RMSE >>', 5702.0)\n",
      "('Decision Tree Std RMSE >>', 471.0)\n"
     ]
    }
   ],
   "source": [
    "dtr_best_score = dtr_search.best_score_\n",
    "print(('Decision Tree Mean RMSE >>', np.round(np.sqrt(-dtr_best_score))))\n",
    "\n",
    "dtr_std = dtr_search.cv_results_['std_test_score'][dtr_search.best_index_]\n",
    "print(('Decision Tree Std RMSE >>', np.round(np.sqrt(dtr_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_depth': [100], 'n_estimators': [100]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "param_grid_rfr = [\n",
    "    {'max_depth': [100,200], 'n_estimators': [100,200]}]\n",
    "\n",
    "rfr_search = GridSearchCV(rfr, param_grid_rfr, cv=5, scoring='neg_mean_squared_error')\n",
    "rfr_search.fit(X_train, train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Forest Mean RMSE >>', 5268.0)\n",
      "('Random Forest Std RMSE >>', 432.0)\n"
     ]
    }
   ],
   "source": [
    "rfr_best_score = rfr_search.best_score_\n",
    "print(('Random Forest Mean RMSE >>',np.round(np.sqrt(-rfr_best_score))))\n",
    "\n",
    "rfr_std = rfr_search.cv_results_['std_test_score'][rfr_search.best_index_]\n",
    "print(('Random Forest Std RMSE >>', np.round(np.sqrt(rfr_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid=[{'n_estimators': [100, 200]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "param_grid_gbr = [\n",
    "    {'n_estimators': [100, 200]}]\n",
    "\n",
    "    \n",
    "gbr_search = GridSearchCV(gbr, param_grid_gbr, cv=5, scoring='neg_mean_squared_error')\n",
    "gbr_search.fit(X_train, train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gradient Boosting Mean RMSE >>', 6469.0)\n",
      "('Gradient Boosting Mean RMSE >>', 374.0)\n"
     ]
    }
   ],
   "source": [
    "gbr_best_score = gbr_search.best_score_\n",
    "print(('Gradient Boosting Mean RMSE >>', np.round(np.sqrt(-gbr_best_score))))\n",
    "\n",
    "gbr_std = gbr_search.cv_results_['std_test_score'][gbr_search.best_index_]\n",
    "print(('Gradient Boosting Mean RMSE >>', np.round(np.sqrt(gbr_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection For Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most important features used in the random forest classifier \n",
    "feature_importance = rfr_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the feature names and their importance for the classifier \n",
    "variables1 = pd.DataFrame((zip(feature_importance)), columns= ['importance'], index= X_train.columns).sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_mazda</th>\n",
       "      <th>x1_200</th>\n",
       "      <th>x0_buick</th>\n",
       "      <th>x1_highlander</th>\n",
       "      <th>x1_fusion</th>\n",
       "      <th>x9_ri</th>\n",
       "      <th>x7_mini-van</th>\n",
       "      <th>x9_ne</th>\n",
       "      <th>x1_malibu</th>\n",
       "      <th>x1_civic</th>\n",
       "      <th>...</th>\n",
       "      <th>x1_cr-v</th>\n",
       "      <th>x10_Old</th>\n",
       "      <th>x0_mercury</th>\n",
       "      <th>x1_passat</th>\n",
       "      <th>x1_optima</th>\n",
       "      <th>x1_santa</th>\n",
       "      <th>x3_lower_power</th>\n",
       "      <th>x1_sonata</th>\n",
       "      <th>x1_liberty</th>\n",
       "      <th>x10_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0_mazda    x1_200  x0_buick  x1_highlander  x1_fusion     x9_ri  \\\n",
       "importance  0.000994  0.000982  0.000916       0.000899   0.000891  0.000857   \n",
       "\n",
       "            x7_mini-van     x9_ne  x1_malibu  x1_civic  ...   x1_cr-v  \\\n",
       "importance     0.000848  0.000847   0.000827  0.000824  ...  0.000252   \n",
       "\n",
       "            x10_Old  x0_mercury  x1_passat  x1_optima  x1_santa  \\\n",
       "importance  0.00025    0.000205    0.00018   0.000172  0.000163   \n",
       "\n",
       "            x3_lower_power  x1_sonata  x1_liberty   x10_New  \n",
       "importance        0.000161   0.000161    0.000095  0.000013  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will inspect the variables that are less than 0.001 important for price\n",
    "features_to_drop1 = variables1.loc[(variables1['importance']<0.001)].T\n",
    "\n",
    "features_to_drop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(features_to_drop1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE:\n",
      "Scores: [5383. 5419. 5418. 5382. 5421.]\n",
      "Mean:  5405.0\n",
      "Stdev: 18.0\n"
     ]
    }
   ],
   "source": [
    "forest_model = rfr_search.best_estimator_\n",
    "forest_scores = cross_val_score(forest_model, X_train, train_price,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "print(('Random Forest RMSE:'))\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline, Interpretable Model, and Final Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the interpretable model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [1000, 3000],\n",
       "                          'splitter': ['random', 'best']}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "param_grid_dtr = [\n",
    "    {'splitter': ['random','best'], 'max_depth': [1000, 3000]}]\n",
    "\n",
    "dtr_search = GridSearchCV(dtr, param_grid_dtr, cv=5, scoring='neg_mean_squared_error')\n",
    "dtr_search.fit(X_train, train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Decision Tree Mean RMSE >>', 5797.0)\n",
      "('Decision Tree Std RMSE >>', 475.0)\n"
     ]
    }
   ],
   "source": [
    "dtr_best_score = dtr_search.best_score_\n",
    "print(('Decision Tree Mean RMSE >>', np.round(np.sqrt(-dtr_best_score))))\n",
    "\n",
    "dtr_std = dtr_search.cv_results_['std_test_score'][dtr_search.best_index_]\n",
    "print(('Decision Tree Std RMSE >>', np.round(np.sqrt(dtr_std))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = dtr_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the test\n",
    "df_test = pd.read_csv('cars_test.csv')\n",
    "\n",
    "#remove zero prices for test\n",
    "zero_price_test = df_test.loc[df_test['price'] == 0]\n",
    "df_test.drop(zero_price_test.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the threshold for the outliers for every numerical variable\n",
    "lower_price1, upper_price1 = f.detect_outliers(df_test['price'])\n",
    "lower_id1, upper_id1 = f.detect_outliers(df_test['id'])\n",
    "lower_year1, upper_year1 = f.detect_outliers(df_test['year'])\n",
    "lower_odometer1, upper_odometer1 = f.detect_outliers(df_test['odometer'])\n",
    "lower_lat1, upper_lat1 = f.detect_outliers(df_test['lat'])\n",
    "lower_long1, upper_long1 = f.detect_outliers(df_test['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering all the records that contain outliers to drop them\n",
    "outliers1 = df_test.loc[(df_test['price'] < lower_price1) | (df_test['price'] > upper_price1) |\n",
    "                        (df_test['id'] < lower_id1) | (df_test['id'] > upper_id1) |\n",
    "                        (df_test['year'] < lower_year1) | (df_test['year'] > upper_year1) |\n",
    "                        (df_test['odometer'] < lower_odometer1) | (df_test['odometer'] > upper_odometer1) |\n",
    "                        (df_test['lat'] < lower_lat1) | (df_test['lat'] > upper_lat1) |\n",
    "                        (df_test['long'] < lower_long1) | (df_test['long'] > upper_long1)]\n",
    "\n",
    "df_test.drop(outliers1.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprate the test data and drop all the columns that I decided to drop during training \n",
    "test_price = df_test['price']\n",
    "test_features = df_test.drop(['price','id','odometer','posting_date','lat','long','region'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the empty rows for the categorical data for the testing set with the most frequent value\n",
    "test_features['type'] = f.fill_cat(test_features['type'])\n",
    "test_features['drive'] = f.fill_cat(test_features['drive'])\n",
    "test_features['transmission'] = f.fill_cat(test_features['transmission'])\n",
    "test_features['fuel'] = f.fill_cat(test_features['fuel'])\n",
    "test_features['cylinders'] = f.fill_cat(test_features['cylinders'])\n",
    "test_features['condition'] = f.fill_cat(test_features['condition'])\n",
    "test_features['model'] = f.fill_cat(test_features['model'])\n",
    "test_features['manufacturer'] = f.fill_cat(test_features['manufacturer'])\n",
    "test_features['paint_color'] = f.fill_cat(test_features['paint_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all the categories of the column that their count is less than 1000 and group them into one group 'other'\n",
    "test_list1 = f.features_list(test_features['manufacturer'],1000)\n",
    "test_features['manufacturer'] = test_features['manufacturer'].replace(test_list1,'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    114487\n",
       "new       6903\n",
       "fair      2552\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put condition into 3 categories\n",
    "mapping_test1 = {'like new':'new', 'excellent':'good','salvage':'fair'}\n",
    "test_features['condition']= test_features['condition'].replace(mapping_test1)\n",
    "test_features['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average        123033\n",
       "more_power        454\n",
       "other             297\n",
       "lower_power       158\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the cylinders column from the word cylinders\n",
    "test_features['cylinders']=test_features['cylinders'].str.replace('cylinders', '')\n",
    "test_features['cylinders']=test_features['cylinders'].astype('object')\n",
    "\n",
    "#put cylinders into 3 categories \n",
    "mapping_test = {'4 ':'average','6 ':'average','8 ':'average','5 ':'average','10 ':'more_power','12 ':'more_power','3 ':'lower_power'}\n",
    "test_features['cylinders'] = test_features['cylinders'].replace(mapping_test)\n",
    "test_features['cylinders'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the values that their count is less than 1000 with other\n",
    "test_list = f.features_list(test_features['model'], 1000)\n",
    "test_features['model']=test_features['model'].replace(test_list,'other')\n",
    "\n",
    "#create a dict that contains every term and its replacment in the model column to replace the terms\n",
    "model_dic_test=f.replace(test_features['model'])\n",
    "test_features['model'] = test_features['model'].replace(model_dic_test)\n",
    "\n",
    "#group the categories with the least effect as others\n",
    "mapping_test = {'odyssey':'other','expedition':'other','colorado':'other','grand caravan':'other','acadia':'other','murano':'other',\n",
    "           '300':'other','sienna':'other'}\n",
    "test_features['model'] = test_features['model'].replace(mapping_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netural    72378\n",
       "dark       28379\n",
       "light      20634\n",
       "custom      2551\n",
       "Name: paint_color, dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin the paint color\n",
    "color_mapping_test={'white':'netural','black':'dark','silver':'netural','red':'light','blue':'dark','grey':'light','green':'light',\n",
    "              'brown':'dark','orange':'light','yellow':'light','purple':'dark'}\n",
    "\n",
    "test_features['paint_color']= test_features['paint_color'].replace(color_mapping_test)\n",
    "test_features['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['year_bins'] = f.bin_years(test_features['year'])\n",
    "\n",
    "test_features['year_bins'] = f.fill_cat(test_features['year_bins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerical variables: (123942, 1)\n",
      "The categorical variables: (123942, 11)\n"
     ]
    }
   ],
   "source": [
    "# seperating the numerical and categorical values for the test \n",
    "test_features_num = test_features.select_dtypes(include=[np.number])\n",
    "test_features_cat = test_features.select_dtypes(exclude=[np.number])\n",
    "print('The numerical variables:', test_features_num.shape)\n",
    "print('The categorical variables:', test_features_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif \n",
    "\n",
    "select = SelectKBest(mutual_info_classif, k=89)\n",
    "\n",
    "numeric_pipeline = Pipeline([('imputer', imputer),('scaler', scaler)])\n",
    "    \n",
    "num_attribs = list(train_features_num_m)\n",
    "cat_attribs = list(train_features_cat_m)\n",
    "    \n",
    "pipeline = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, num_attribs),\n",
    "        (\"cat\", cat_encoder, cat_attribs)])\n",
    "\n",
    "train_prepared= pipeline.fit_transform(train_features)\n",
    "test_prepared = pipeline.transform(test_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_pipeline = Pipeline([('preperation', pipeline), ('select', select), ('final_model', final_model)])\n",
    "\n",
    "train_pred= full_pipeline.fit(train_features, train_price)\n",
    "test_pred = full_pipeline.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8040.17359177304"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mse = mean_squared_error(test_price, test_pred)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
